# ğŸ–¼ï¸ CIFAR-10 CNN Classifier

Um classificador de imagens usando Redes Neurais Convolucionais (CNN) para o dataset CIFAR-10, implementado em PyTorch com uma arquitetura moderna e tÃ©cnicas de regularizaÃ§Ã£o avanÃ§adas.

## ğŸ¯ Sobre o Projeto

Este projeto implementa uma CNN profunda para classificaÃ§Ã£o das 10 classes do dataset CIFAR-10:
- âœˆï¸ AviÃ£o
- ğŸš— AutomÃ³vel  
- ğŸ¦ PÃ¡ssaro
- ğŸ± Gato
- ğŸ¦Œ Cervo
- ğŸ• Cachorro
- ğŸ¸ Sapo
- ğŸ Cavalo
- ğŸš¢ Navio
- ğŸš› CaminhÃ£o

## ğŸ—ï¸ Arquitetura da Rede

A CNN implementada possui uma arquitetura robusta com:

- **5 blocos convolucionais** com filtros crescentes (32 â†’ 64 â†’ 128 â†’ 256 â†’ 512)
- **Batch Normalization** para estabilizar o treinamento
- **Dropout** para regularizaÃ§Ã£o (0.25, 0.3, 0.5)
- **MaxPooling** para reduÃ§Ã£o dimensional
- **Classificador totalmente conectado** com 1024 neurÃ´nios

### TÃ©cnicas de RegularizaÃ§Ã£o
- Data augmentation (crops aleatÃ³rios, flip horizontal, AutoAugment)
- NormalizaÃ§Ã£o com estatÃ­sticas do CIFAR-10
- Learning rate scheduling (decay exponencial)
- Early stopping baseado na acurÃ¡cia de validaÃ§Ã£o

## ğŸ“ Estrutura do Projeto

```
CNNforCIFAR10/
â”œâ”€â”€ config.py          # ConfiguraÃ§Ãµes e hiperparÃ¢metros
â”œâ”€â”€ data.py            # Carregamento e prÃ©-processamento dos dados
â”œâ”€â”€ model.py           # DefiniÃ§Ã£o da arquitetura CNN
â”œâ”€â”€ train.py           # Loop de treinamento e avaliaÃ§Ã£o
â”œâ”€â”€ plot.py            # VisualizaÃ§Ã£o dos resultados
â”œâ”€â”€ main.py            # Script principal
â””â”€â”€ README.md          # Este arquivo
```

## âš™ï¸ ConfiguraÃ§Ãµes

| ParÃ¢metro | Valor | DescriÃ§Ã£o |
|-----------|-------|-----------|
| Learning Rate | 0.001 | Taxa de aprendizado inicial |
| Batch Size | 16 | Tamanho do lote |
| Gamma | 0.97 | Fator de decay do learning rate |
| Epochs | 100 | NÃºmero de Ã©pocas |
| Image Size | 32Ã—32 | DimensÃ£o das imagens |

## ğŸš€ Como Usar

### PrÃ©-requisitos

```bash
pip install torch torchvision matplotlib
```

### Executando o Treinamento

```bash
python main.py
```

O script irÃ¡:
1. Detectar automaticamente se GPU estÃ¡ disponÃ­vel
2. Baixar o dataset CIFAR-10 (primeira execuÃ§Ã£o)
3. Treinar o modelo com visualizaÃ§Ã£o em tempo real
4. Salvar o melhor modelo como `best_model.pth`
5. Gerar grÃ¡ficos de treinamento em `training_plot.png`

## ğŸ“Š SaÃ­das do Treinamento

Durante o treinamento, vocÃª verÃ¡:

```
Usando dispositivo: cuda
Epoch [1/100] | Train Loss: 1.8234 | Val Loss: 1.6543 | Val Acc: 42.15%
Epoch [2/100] | Train Loss: 1.5678 | Val Loss: 1.4321 | Val Acc: 48.72%
...
Melhor acurÃ¡cia de validaÃ§Ã£o: 89.45%
```

### VisualizaÃ§Ãµes Geradas

- **GrÃ¡fico de Loss**: Acompanha a evoluÃ§Ã£o do loss de treino e validaÃ§Ã£o
- **GrÃ¡fico de AcurÃ¡cia**: Monitora a acurÃ¡cia de validaÃ§Ã£o ao longo das Ã©pocas

## ğŸ¯ CaracterÃ­sticas TÃ©cnicas

### Data Augmentation
- **RandomCrop**: Crops aleatÃ³rios com padding
- **RandomHorizontalFlip**: InversÃ£o horizontal aleatÃ³ria  
- **AutoAugment**: PolÃ­ticas automÃ¡ticas de augmentaÃ§Ã£o para CIFAR-10

### OtimizaÃ§Ã£o
- **Optimizer**: AdamW (versÃ£o melhorada do Adam)
- **Scheduler**: ExponentialLR para decay do learning rate
- **Loss Function**: CrossEntropyLoss

### Hardware
- **GPU**: UtilizaÃ§Ã£o automÃ¡tica se disponÃ­vel
- **CPU**: ParalelizaÃ§Ã£o com mÃºltiplos workers no DataLoader

## ğŸ“ˆ Resultados Esperados

Com esta arquitetura e configuraÃ§Ãµes, vocÃª pode esperar:
- **AcurÃ¡cia de validaÃ§Ã£o**: 85-93%
- **Tempo de treinamento**: ~30-60 minutos (GPU) / 3-5 horas (CPU)
- **ConvergÃªncia**: Tipicamente entre 50-80 Ã©pocas

## ğŸ”§ PersonalizaÃ§Ã£o

### Modificar HiperparÃ¢metros
Edite o arquivo `config.py`:

```python
LEARNING_RATE = 0.0005  # Reduzir para treinamento mais estÃ¡vel
BATCH_SIZE = 32         # Aumentar se tiver mais VRAM
EPOCHS = 150            # Mais Ã©pocas para melhor convergÃªncia
```

### Ajustar Arquitetura
Modifique o arquivo `model.py` para:
- Adicionar/remover camadas
- Alterar tamanhos de filtros
- Ajustar dropout rates

## ğŸ¤ ContribuiÃ§Ãµes

Sinta-se Ã  vontade para:
- Reportar bugs
- Sugerir melhorias
- Implementar novas features
- Otimizar a arquitetura

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---
